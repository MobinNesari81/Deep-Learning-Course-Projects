{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß© CIFAR-10 Autoencoder Project\n",
    "\n",
    "This notebook demonstrates the use of an Autoencoder for dimensionality reduction and image reconstruction on the CIFAR-10 dataset. The model is trained to compress and then reconstruct images, learning meaningful patterns in an unsupervised fashion. Let's dive in! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:17:18.304472Z",
     "iopub.status.busy": "2023-01-03T19:17:18.304016Z",
     "iopub.status.idle": "2023-01-03T19:17:20.367085Z",
     "shell.execute_reply": "2023-01-03T19:17:20.365880Z",
     "shell.execute_reply.started": "2023-01-03T19:17:18.304398Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries üìö\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt  # For plotting üñºÔ∏è\n",
    "\n",
    "# Setting random seed for reproducibility üîÑ\n",
    "SEED = 87\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:17:20.377375Z",
     "iopub.status.busy": "2023-01-03T19:17:20.374579Z",
     "iopub.status.idle": "2023-01-03T19:17:20.385465Z",
     "shell.execute_reply": "2023-01-03T19:17:20.384394Z",
     "shell.execute_reply.started": "2023-01-03T19:17:20.377337Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_model(encoder, decoder):\n",
    "    \"\"\"Prints the architecture of the encoder and decoder models.\"\"\"\n",
    "    print(\"============== Encoder ==============\")\n",
    "    print(encoder)\n",
    "    print(\"============== Decoder ==============\")\n",
    "    print(decoder)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T21:48:03.948756Z",
     "iopub.status.busy": "2023-01-02T21:48:03.948400Z",
     "iopub.status.idle": "2023-01-02T21:48:03.953757Z",
     "shell.execute_reply": "2023-01-02T21:48:03.952816Z",
     "shell.execute_reply.started": "2023-01-02T21:48:03.948725Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    \"\"\"Creates and initializes the Autoencoder model.\"\"\"\n",
    "    autoencoder = Autoencoder()\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU to speed up training. üöÄ\")\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T21:48:04.709154Z",
     "iopub.status.busy": "2023-01-02T21:48:04.708765Z",
     "iopub.status.idle": "2023-01-02T21:48:04.714830Z",
     "shell.execute_reply": "2023-01-02T21:48:04.713568Z",
     "shell.execute_reply.started": "2023-01-02T21:48:04.709119Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model1(encoder):\n",
    "    autoencoder = AutoEncoder1(encoder)\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:17:20.392238Z",
     "iopub.status.busy": "2023-01-03T19:17:20.390950Z",
     "iopub.status.idle": "2023-01-03T19:17:20.400385Z",
     "shell.execute_reply": "2023-01-03T19:17:20.399336Z",
     "shell.execute_reply.started": "2023-01-03T19:17:20.392198Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_torch_vars(x):\n",
    "    \"\"\"Moves the tensor to GPU if available.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:17:20.404239Z",
     "iopub.status.busy": "2023-01-03T19:17:20.402828Z",
     "iopub.status.idle": "2023-01-03T19:17:20.413795Z",
     "shell.execute_reply": "2023-01-03T19:17:20.412668Z",
     "shell.execute_reply.started": "2023-01-03T19:17:20.404202Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.cpu().detach().numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T21:49:24.473965Z",
     "iopub.status.busy": "2023-01-02T21:49:24.473008Z",
     "iopub.status.idle": "2023-01-02T21:49:24.483269Z",
     "shell.execute_reply": "2023-01-02T21:49:24.482163Z",
     "shell.execute_reply.started": "2023-01-02T21:49:24.473928Z"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "# \t\t\tnn.Conv2d(48, 96, 4, stride=2, padding=1),           # [batch, 96, 2, 2]\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "#             nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T21:49:25.141575Z",
     "iopub.status.busy": "2023-01-02T21:49:25.140604Z",
     "iopub.status.idle": "2023-01-02T21:49:37.796566Z",
     "shell.execute_reply": "2023-01-02T21:49:37.795557Z",
     "shell.execute_reply.started": "2023-01-02T21:49:25.141538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "autoencoder = create_model()\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this if you have pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T07:32:11.995037Z",
     "iopub.status.busy": "2022-12-19T07:32:11.994689Z",
     "iopub.status.idle": "2022-12-19T07:32:17.605975Z",
     "shell.execute_reply": "2022-12-19T07:32:17.604875Z",
     "shell.execute_reply.started": "2022-12-19T07:32:11.995001Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "autoencoder.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/autoencoder.pkl\"))\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "images = Variable(images.cuda())\n",
    "\n",
    "decoded_imgs = autoencoder(images)[1]\n",
    "imshow(torchvision.utils.make_grid(decoded_imgs.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T05:15:54.021321Z",
     "iopub.status.busy": "2022-12-19T05:15:54.014631Z",
     "iopub.status.idle": "2022-12-19T05:15:54.031791Z",
     "shell.execute_reply": "2022-12-19T05:15:54.030539Z",
     "shell.execute_reply.started": "2022-12-19T05:15:54.021242Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T05:15:54.040766Z",
     "iopub.status.busy": "2022-12-19T05:15:54.038475Z",
     "iopub.status.idle": "2022-12-19T05:19:46.471998Z",
     "shell.execute_reply": "2022-12-19T05:19:46.470672Z",
     "shell.execute_reply.started": "2022-12-19T05:15:54.040700Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, _) in enumerate(trainloader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = autoencoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(autoencoder.state_dict(), \"./weights/autoencoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:17:20.422804Z",
     "iopub.status.busy": "2023-01-03T19:17:20.419139Z",
     "iopub.status.idle": "2023-01-03T19:17:20.437204Z",
     "shell.execute_reply": "2023-01-03T19:17:20.436240Z",
     "shell.execute_reply.started": "2023-01-03T19:17:20.422755Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, size=1000, transform=None):\n",
    "        indexes = random.sample(range(0, 50000), size)\n",
    "        group1 = indexes[:size//2]\n",
    "        group2 = indexes[size//2:]\n",
    "        self.train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "        self.indexes = []\n",
    "        for i in group1:\n",
    "            for j in group2:\n",
    "                self.indexes.append((i, j))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        index1, index2 = self.indexes[idx]\n",
    "        img1 = self.train_set[index1][0]\n",
    "        img2 = self.train_set[index2][0]\n",
    "        result = img1 + img2\n",
    "        result = result / 2\n",
    "        return result, (img1, img2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:17:21.266292Z",
     "iopub.status.busy": "2023-01-03T19:17:21.265539Z",
     "iopub.status.idle": "2023-01-03T19:17:29.630945Z",
     "shell.execute_reply": "2023-01-03T19:17:29.629945Z",
     "shell.execute_reply.started": "2023-01-03T19:17:21.266256Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_set = CustomDataset(1000)\n",
    "custom_loader = torch.utils.data.DataLoader(custom_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:15:58.516444Z",
     "iopub.status.busy": "2022-12-24T05:15:58.516072Z",
     "iopub.status.idle": "2022-12-24T05:15:58.523735Z",
     "shell.execute_reply": "2022-12-24T05:15:58.522560Z",
     "shell.execute_reply.started": "2022-12-24T05:15:58.516411Z"
    }
   },
   "outputs": [],
   "source": [
    "class AutoEncoder1(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(AutoEncoder1, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "#             nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:05:27.439966Z",
     "iopub.status.busy": "2022-12-19T12:05:27.439608Z",
     "iopub.status.idle": "2022-12-19T12:05:27.448311Z",
     "shell.execute_reply": "2022-12-19T12:05:27.447129Z",
     "shell.execute_reply.started": "2022-12-19T12:05:27.439936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "autoencoder1 = create_model1(autoencoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T07:33:32.795209Z",
     "iopub.status.busy": "2022-12-19T07:33:32.794807Z",
     "iopub.status.idle": "2022-12-19T07:33:32.802245Z",
     "shell.execute_reply": "2022-12-19T07:33:32.800951Z",
     "shell.execute_reply.started": "2022-12-19T07:33:32.795174Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, param in enumerate(autoencoder1.parameters()):\n",
    "    print(i, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T07:33:03.123274Z",
     "iopub.status.busy": "2022-12-19T07:33:03.122708Z",
     "iopub.status.idle": "2022-12-19T07:33:03.129405Z",
     "shell.execute_reply": "2022-12-19T07:33:03.128259Z",
     "shell.execute_reply.started": "2022-12-19T07:33:03.123237Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, param in enumerate(autoencoder1.parameters()):\n",
    "    if i < 6:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T07:58:58.766702Z",
     "iopub.status.busy": "2022-12-19T07:58:58.766143Z",
     "iopub.status.idle": "2022-12-19T07:58:58.777528Z",
     "shell.execute_reply": "2022-12-19T07:58:58.776648Z",
     "shell.execute_reply.started": "2022-12-19T07:58:58.766653Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, autoencoder1.parameters()))\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:05:30.755238Z",
     "iopub.status.busy": "2022-12-19T12:05:30.754862Z",
     "iopub.status.idle": "2022-12-19T12:05:30.778920Z",
     "shell.execute_reply": "2022-12-19T12:05:30.778049Z",
     "shell.execute_reply.started": "2022-12-19T12:05:30.755204Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "autoencoder1.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/autoencoder1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T07:33:22.539934Z",
     "iopub.status.busy": "2022-12-19T07:33:22.539151Z",
     "iopub.status.idle": "2022-12-19T07:33:23.002947Z",
     "shell.execute_reply": "2022-12-19T07:33:23.001802Z",
     "shell.execute_reply.started": "2022-12-19T07:33:22.539897Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    imshow(inputs[0])\n",
    "    imshow(outputs1[0])\n",
    "    imshow(outputs2[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T07:33:24.519540Z",
     "iopub.status.busy": "2022-12-19T07:33:24.518793Z",
     "iopub.status.idle": "2022-12-19T07:33:24.527239Z",
     "shell.execute_reply": "2022-12-19T07:33:24.526135Z",
     "shell.execute_reply.started": "2022-12-19T07:33:24.519501Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T07:59:03.004706Z",
     "iopub.status.busy": "2022-12-19T07:59:03.004353Z",
     "iopub.status.idle": "2022-12-19T08:48:51.065488Z",
     "shell.execute_reply": "2022-12-19T08:48:51.064355Z",
     "shell.execute_reply.started": "2022-12-19T07:59:03.004675Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = autoencoder1(inputs)\n",
    "        loss = criterion(outputs, outputs1)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch_counter == 4:\n",
    "        epoch_counter = -1\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(autoencoder1.state_dict(), \"./weights/autoencoder1.pkl\")\n",
    "    epoch_counter += 1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(autoencoder1.state_dict(), \"./weights/autoencoder1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T08:48:51.068009Z",
     "iopub.status.busy": "2022-12-19T08:48:51.067642Z",
     "iopub.status.idle": "2022-12-19T08:48:51.074983Z",
     "shell.execute_reply": "2022-12-19T08:48:51.074011Z",
     "shell.execute_reply.started": "2022-12-19T08:48:51.067968Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T08:48:51.077025Z",
     "iopub.status.busy": "2022-12-19T08:48:51.076432Z",
     "iopub.status.idle": "2022-12-19T08:48:51.655035Z",
     "shell.execute_reply": "2022-12-19T08:48:51.653939Z",
     "shell.execute_reply.started": "2022-12-19T08:48:51.076989Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image: \")\n",
    "    imshow(autoencoder1(inputs[0])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T21:49:53.737606Z",
     "iopub.status.busy": "2023-01-02T21:49:53.736989Z",
     "iopub.status.idle": "2023-01-02T21:49:54.711098Z",
     "shell.execute_reply": "2023-01-02T21:49:54.710064Z",
     "shell.execute_reply.started": "2023-01-02T21:49:53.737571Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set = CustomDataset(1000)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T08:48:52.643605Z",
     "iopub.status.busy": "2022-12-19T08:48:52.643230Z",
     "iopub.status.idle": "2022-12-19T08:48:53.434111Z",
     "shell.execute_reply": "2022-12-19T08:48:53.433016Z",
     "shell.execute_reply.started": "2022-12-19T08:48:52.643568Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image: \")\n",
    "    imshow(autoencoder1(inputs[0])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:05:40.273044Z",
     "iopub.status.busy": "2022-12-19T12:05:40.272671Z",
     "iopub.status.idle": "2022-12-19T12:05:40.281721Z",
     "shell.execute_reply": "2022-12-19T12:05:40.280180Z",
     "shell.execute_reply.started": "2022-12-19T12:05:40.273012Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder2 = create_model1(autoencoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:05:42.868402Z",
     "iopub.status.busy": "2022-12-19T12:05:42.867995Z",
     "iopub.status.idle": "2022-12-19T12:05:42.888200Z",
     "shell.execute_reply": "2022-12-19T12:05:42.887103Z",
     "shell.execute_reply.started": "2022-12-19T12:05:42.868365Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "autoencoder2.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/autoencoder2.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T08:48:53.447325Z",
     "iopub.status.busy": "2022-12-19T08:48:53.446959Z",
     "iopub.status.idle": "2022-12-19T08:48:53.454479Z",
     "shell.execute_reply": "2022-12-19T08:48:53.453592Z",
     "shell.execute_reply.started": "2022-12-19T08:48:53.447290Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, param in enumerate(autoencoder2.parameters()):\n",
    "    if i < 6:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T08:48:53.456903Z",
     "iopub.status.busy": "2022-12-19T08:48:53.455594Z",
     "iopub.status.idle": "2022-12-19T08:48:53.465476Z",
     "shell.execute_reply": "2022-12-19T08:48:53.464511Z",
     "shell.execute_reply.started": "2022-12-19T08:48:53.456868Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, param in enumerate(autoencoder2.parameters()):\n",
    "    print(i, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T08:48:53.467885Z",
     "iopub.status.busy": "2022-12-19T08:48:53.466820Z",
     "iopub.status.idle": "2022-12-19T08:48:53.475810Z",
     "shell.execute_reply": "2022-12-19T08:48:53.475109Z",
     "shell.execute_reply.started": "2022-12-19T08:48:53.467851Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, autoencoder2.parameters()))\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T08:48:53.479701Z",
     "iopub.status.busy": "2022-12-19T08:48:53.479114Z",
     "iopub.status.idle": "2022-12-19T10:52:06.743348Z",
     "shell.execute_reply": "2022-12-19T10:52:06.742154Z",
     "shell.execute_reply.started": "2022-12-19T08:48:53.479674Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = autoencoder2(inputs)\n",
    "        loss = criterion(outputs, outputs2)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(autoencoder2.state_dict(), \"./weights/autoencoder2.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(autoencoder2.state_dict(), \"./weights/autoencoder2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T10:52:06.746272Z",
     "iopub.status.busy": "2022-12-19T10:52:06.745896Z",
     "iopub.status.idle": "2022-12-19T10:52:07.316783Z",
     "shell.execute_reply": "2022-12-19T10:52:07.315700Z",
     "shell.execute_reply.started": "2022-12-19T10:52:06.746234Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image: \")\n",
    "    imshow(autoencoder2(inputs[0])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:16:08.970772Z",
     "iopub.status.busy": "2022-12-24T05:16:08.970313Z",
     "iopub.status.idle": "2022-12-24T05:16:08.978454Z",
     "shell.execute_reply": "2022-12-24T05:16:08.977475Z",
     "shell.execute_reply.started": "2022-12-24T05:16:08.970731Z"
    }
   },
   "outputs": [],
   "source": [
    "class MainAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder1, decoder2):\n",
    "        super(MainAutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder1 = decoder1\n",
    "        self.decoder2 = decoder2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded1 = self.decoder1(encoded)\n",
    "        decoded2 = self.decoder2(encoded)\n",
    "        return encoded, decoded1, decoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:16:10.361083Z",
     "iopub.status.busy": "2022-12-24T05:16:10.360724Z",
     "iopub.status.idle": "2022-12-24T05:16:10.366909Z",
     "shell.execute_reply": "2022-12-24T05:16:10.365605Z",
     "shell.execute_reply.started": "2022-12-24T05:16:10.361052Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_main_model(encoder, decoder1, decoder2):\n",
    "    autoencoder = MainAutoEncoder(encoder, decoder1, decoder2)\n",
    "#     print_model(autoencoder.encoder, autoencoder.decoder1, autoencoder.decoder2)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:06:26.148552Z",
     "iopub.status.busy": "2022-12-19T12:06:26.148136Z",
     "iopub.status.idle": "2022-12-19T12:06:26.159335Z",
     "shell.execute_reply": "2022-12-19T12:06:26.158107Z",
     "shell.execute_reply.started": "2022-12-19T12:06:26.148515Z"
    }
   },
   "outputs": [],
   "source": [
    "main_model = create_main_model(autoencoder.encoder, autoencoder1.decoder, autoencoder2.decoder)\n",
    "main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:07:26.804273Z",
     "iopub.status.busy": "2022-12-19T12:07:26.803839Z",
     "iopub.status.idle": "2022-12-19T12:07:26.837757Z",
     "shell.execute_reply": "2022-12-19T12:07:26.835501Z",
     "shell.execute_reply.started": "2022-12-19T12:07:26.804233Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "main_model.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/main_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:07:45.866213Z",
     "iopub.status.busy": "2022-12-19T12:07:45.865819Z",
     "iopub.status.idle": "2022-12-19T12:07:45.873984Z",
     "shell.execute_reply": "2022-12-19T12:07:45.872909Z",
     "shell.execute_reply.started": "2022-12-19T12:07:45.866176Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(main_model.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:07:47.992638Z",
     "iopub.status.busy": "2022-12-19T12:07:47.991986Z",
     "iopub.status.idle": "2022-12-19T12:07:47.997906Z",
     "shell.execute_reply": "2022-12-19T12:07:47.996836Z",
     "shell.execute_reply.started": "2022-12-19T12:07:47.992601Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(main_model.parameters()):\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:07:52.272874Z",
     "iopub.status.busy": "2022-12-19T12:07:52.272498Z",
     "iopub.status.idle": "2022-12-19T12:07:52.279451Z",
     "shell.execute_reply": "2022-12-19T12:07:52.278342Z",
     "shell.execute_reply.started": "2022-12-19T12:07:52.272841Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(main_model.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:08:02.819976Z",
     "iopub.status.busy": "2022-12-19T12:08:02.819508Z",
     "iopub.status.idle": "2022-12-19T12:08:02.830947Z",
     "shell.execute_reply": "2022-12-19T12:08:02.829748Z",
     "shell.execute_reply.started": "2022-12-19T12:08:02.819932Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, main_model.parameters()))\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T12:09:14.810291Z",
     "iopub.status.busy": "2022-12-19T12:09:14.809904Z",
     "iopub.status.idle": "2022-12-19T14:37:27.311227Z",
     "shell.execute_reply": "2022-12-19T14:37:27.310101Z",
     "shell.execute_reply.started": "2022-12-19T12:09:14.810257Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, output1, output2 = main_model(inputs)\n",
    "        loss = (criterion(output1, outputs1) + criterion(output2, outputs2)) / 2\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(main_model.state_dict(), \"./weights/main_model.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(main_model.state_dict(), \"./weights/main_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T14:43:45.545045Z",
     "iopub.status.busy": "2022-12-19T14:43:45.544020Z",
     "iopub.status.idle": "2022-12-19T14:43:46.237941Z",
     "shell.execute_reply": "2022-12-19T14:43:46.236876Z",
     "shell.execute_reply.started": "2022-12-19T14:43:45.545002Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customise encoder and decoder for denoising mean image and convert it to first image. Then we use $x_2 = 2 \\times \\frac{x_1 + x_2}{2} - x_1$ to discover second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T14:45:52.534893Z",
     "iopub.status.busy": "2022-12-19T14:45:52.533932Z",
     "iopub.status.idle": "2022-12-19T14:45:52.545835Z",
     "shell.execute_reply": "2022-12-19T14:45:52.544762Z",
     "shell.execute_reply.started": "2022-12-19T14:45:52.534850Z"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "# \t\t\tnn.Conv2d(48, 96, 4, stride=2, padding=1),           # [batch, 96, 2, 2]\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "#             nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T14:46:07.294114Z",
     "iopub.status.busy": "2022-12-19T14:46:07.293580Z",
     "iopub.status.idle": "2022-12-19T14:46:07.316962Z",
     "shell.execute_reply": "2022-12-19T14:46:07.316111Z",
     "shell.execute_reply.started": "2022-12-19T14:46:07.294042Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = create_model()\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T14:46:44.123114Z",
     "iopub.status.busy": "2022-12-19T14:46:44.122469Z",
     "iopub.status.idle": "2022-12-19T14:46:44.128298Z",
     "shell.execute_reply": "2022-12-19T14:46:44.127275Z",
     "shell.execute_reply.started": "2022-12-19T14:46:44.123045Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model2.parameters())\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T14:49:43.952442Z",
     "iopub.status.busy": "2022-12-19T14:49:43.952035Z",
     "iopub.status.idle": "2022-12-19T17:02:18.083612Z",
     "shell.execute_reply": "2022-12-19T17:02:18.081627Z",
     "shell.execute_reply.started": "2022-12-19T14:49:43.952408Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = model2(inputs)\n",
    "        loss = criterion(outputs, outputs1)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(model2.state_dict(), \"./weights/model2.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(model2.state_dict(), \"./weights/model2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T17:02:18.088143Z",
     "iopub.status.busy": "2022-12-19T17:02:18.086920Z",
     "iopub.status.idle": "2022-12-19T17:02:18.862885Z",
     "shell.execute_reply": "2022-12-19T17:02:18.861550Z",
     "shell.execute_reply.started": "2022-12-19T17:02:18.088095Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T19:49:41.824386Z",
     "iopub.status.busy": "2022-12-19T19:49:41.823935Z",
     "iopub.status.idle": "2022-12-19T19:49:41.910954Z",
     "shell.execute_reply": "2022-12-19T19:49:41.909451Z",
     "shell.execute_reply.started": "2022-12-19T19:49:41.824298Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(model2(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(2 * inputs[0] - model2(inputs[0])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase Latent Space Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:25:30.132402Z",
     "iopub.status.busy": "2022-12-24T05:25:30.131990Z",
     "iopub.status.idle": "2022-12-24T05:25:30.144910Z",
     "shell.execute_reply": "2022-12-24T05:25:30.143935Z",
     "shell.execute_reply.started": "2022-12-24T05:25:30.132370Z"
    }
   },
   "outputs": [],
   "source": [
    "class BiggerAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiggerAutoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(48, 96, 4, stride=2, padding=1),           # [batch, 96, 2, 2]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:16:23.887694Z",
     "iopub.status.busy": "2022-12-24T05:16:23.886617Z",
     "iopub.status.idle": "2022-12-24T05:16:23.893277Z",
     "shell.execute_reply": "2022-12-24T05:16:23.892061Z",
     "shell.execute_reply.started": "2022-12-24T05:16:23.887610Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bigger_model():\n",
    "    autoencoder = BiggerAutoencoder()\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:16:28.607900Z",
     "iopub.status.busy": "2022-12-24T05:16:28.607195Z",
     "iopub.status.idle": "2022-12-24T05:16:30.600340Z",
     "shell.execute_reply": "2022-12-24T05:16:30.599051Z",
     "shell.execute_reply.started": "2022-12-24T05:16:28.607862Z"
    }
   },
   "outputs": [],
   "source": [
    "bigger_encoder = create_bigger_model()\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "custom_set = CustomDataset(1000)\n",
    "custom_loader = torch.utils.data.DataLoader(custom_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = CustomDataset(1000)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:16:42.337908Z",
     "iopub.status.busy": "2022-12-24T05:16:42.337438Z",
     "iopub.status.idle": "2022-12-24T05:16:42.381533Z",
     "shell.execute_reply": "2022-12-24T05:16:42.380551Z",
     "shell.execute_reply.started": "2022-12-24T05:16:42.337864Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "bigger_encoder.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/bigger_encoder.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:24:33.203786Z",
     "iopub.status.busy": "2022-12-23T16:24:33.203425Z",
     "iopub.status.idle": "2022-12-23T16:24:33.209157Z",
     "shell.execute_reply": "2022-12-23T16:24:33.208202Z",
     "shell.execute_reply.started": "2022-12-23T16:24:33.203743Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(bigger_encoder.parameters())\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:24:35.371123Z",
     "iopub.status.busy": "2022-12-23T16:24:35.370775Z",
     "iopub.status.idle": "2022-12-23T16:39:18.978929Z",
     "shell.execute_reply": "2022-12-23T16:39:18.977862Z",
     "shell.execute_reply.started": "2022-12-23T16:24:35.371094Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, _) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = bigger_encoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(bigger_encoder.state_dict(), \"./weights/bigger_encoder.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(bigger_encoder.state_dict(), \"./weights/bigger_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:39:18.981641Z",
     "iopub.status.busy": "2022-12-23T16:39:18.981246Z",
     "iopub.status.idle": "2022-12-23T16:39:19.407722Z",
     "shell.execute_reply": "2022-12-23T16:39:19.406604Z",
     "shell.execute_reply.started": "2022-12-23T16:39:18.981601Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(bigger_encoder(inputs[0])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:17:32.157692Z",
     "iopub.status.busy": "2022-12-24T05:17:32.157319Z",
     "iopub.status.idle": "2022-12-24T05:17:32.165165Z",
     "shell.execute_reply": "2022-12-24T05:17:32.164121Z",
     "shell.execute_reply.started": "2022-12-24T05:17:32.157652Z"
    }
   },
   "outputs": [],
   "source": [
    "class BiggerAutoEncoder1(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(BiggerAutoEncoder1, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:19:07.851838Z",
     "iopub.status.busy": "2022-12-24T05:19:07.851447Z",
     "iopub.status.idle": "2022-12-24T05:19:07.857335Z",
     "shell.execute_reply": "2022-12-24T05:19:07.856349Z",
     "shell.execute_reply.started": "2022-12-24T05:19:07.851805Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bigger_model1(encoder):\n",
    "    autoencoder = BiggerAutoEncoder1(encoder)\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:39:19.432495Z",
     "iopub.status.busy": "2022-12-23T16:39:19.431974Z",
     "iopub.status.idle": "2022-12-23T16:39:19.443903Z",
     "shell.execute_reply": "2022-12-23T16:39:19.442597Z",
     "shell.execute_reply.started": "2022-12-23T16:39:19.432460Z"
    }
   },
   "outputs": [],
   "source": [
    "big_autoencoder1 = create_bigger_model1(bigger_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:39:19.446116Z",
     "iopub.status.busy": "2022-12-23T16:39:19.445724Z",
     "iopub.status.idle": "2022-12-23T16:39:19.473915Z",
     "shell.execute_reply": "2022-12-23T16:39:19.472985Z",
     "shell.execute_reply.started": "2022-12-23T16:39:19.446081Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "big_autoencoder1.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/big_autoencoder1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:39:19.475864Z",
     "iopub.status.busy": "2022-12-23T16:39:19.475220Z",
     "iopub.status.idle": "2022-12-23T16:39:19.482160Z",
     "shell.execute_reply": "2022-12-23T16:39:19.481193Z",
     "shell.execute_reply.started": "2022-12-23T16:39:19.475829Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(big_autoencoder1.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:39:19.484211Z",
     "iopub.status.busy": "2022-12-23T16:39:19.483624Z",
     "iopub.status.idle": "2022-12-23T16:39:19.491195Z",
     "shell.execute_reply": "2022-12-23T16:39:19.490318Z",
     "shell.execute_reply.started": "2022-12-23T16:39:19.484174Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(big_autoencoder1.parameters()):\n",
    "    if index < 8:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:39:19.493605Z",
     "iopub.status.busy": "2022-12-23T16:39:19.493309Z",
     "iopub.status.idle": "2022-12-23T16:39:19.502054Z",
     "shell.execute_reply": "2022-12-23T16:39:19.500860Z",
     "shell.execute_reply.started": "2022-12-23T16:39:19.493580Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(big_autoencoder1.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T16:41:47.228153Z",
     "iopub.status.busy": "2022-12-23T16:41:47.227189Z",
     "iopub.status.idle": "2022-12-23T16:41:47.235143Z",
     "shell.execute_reply": "2022-12-23T16:41:47.234081Z",
     "shell.execute_reply.started": "2022-12-23T16:41:47.228115Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, big_autoencoder1.parameters()))\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-12-23T16:41:48.816368Z",
     "iopub.status.busy": "2022-12-23T16:41:48.815985Z",
     "iopub.status.idle": "2022-12-23T17:33:47.787472Z",
     "shell.execute_reply": "2022-12-23T17:33:47.785568Z",
     "shell.execute_reply.started": "2022-12-23T16:41:48.816319Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = big_autoencoder1(inputs)\n",
    "        loss = criterion(outputs, outputs1)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch_counter == 4:\n",
    "        epoch_counter = -1\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(big_autoencoder1.state_dict(), \"./weights/big_autoencoder1.pkl\")\n",
    "    epoch_counter += 1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(big_autoencoder1.state_dict(), \"./weights/big_autoencoder1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T17:33:47.790320Z",
     "iopub.status.busy": "2022-12-23T17:33:47.789715Z",
     "iopub.status.idle": "2022-12-23T17:33:48.261848Z",
     "shell.execute_reply": "2022-12-23T17:33:48.260769Z",
     "shell.execute_reply.started": "2022-12-23T17:33:47.790278Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(big_autoencoder1(inputs[0])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T17:33:48.265431Z",
     "iopub.status.busy": "2022-12-23T17:33:48.264446Z",
     "iopub.status.idle": "2022-12-23T17:33:48.276220Z",
     "shell.execute_reply": "2022-12-23T17:33:48.275295Z",
     "shell.execute_reply.started": "2022-12-23T17:33:48.265388Z"
    }
   },
   "outputs": [],
   "source": [
    "big_autoencoder2 = create_bigger_model1(bigger_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T17:33:48.278470Z",
     "iopub.status.busy": "2022-12-23T17:33:48.278196Z",
     "iopub.status.idle": "2022-12-23T17:33:48.284434Z",
     "shell.execute_reply": "2022-12-23T17:33:48.283385Z",
     "shell.execute_reply.started": "2022-12-23T17:33:48.278444Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(big_autoencoder2.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T17:33:48.286781Z",
     "iopub.status.busy": "2022-12-23T17:33:48.286102Z",
     "iopub.status.idle": "2022-12-23T17:33:48.292816Z",
     "shell.execute_reply": "2022-12-23T17:33:48.291655Z",
     "shell.execute_reply.started": "2022-12-23T17:33:48.286747Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, big_autoencoder2.parameters()))\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-12-23T17:33:48.294922Z",
     "iopub.status.busy": "2022-12-23T17:33:48.294389Z",
     "iopub.status.idle": "2022-12-23T18:40:25.263262Z",
     "shell.execute_reply": "2022-12-23T18:40:25.262066Z",
     "shell.execute_reply.started": "2022-12-23T17:33:48.294887Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = big_autoencoder2(inputs)\n",
    "        loss = criterion(outputs, outputs2)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch_counter == 4:\n",
    "        epoch_counter = -1\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(big_autoencoder2.state_dict(), \"./weights/big_autoencoder2.pkl\")\n",
    "    epoch_counter += 1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(big_autoencoder2.state_dict(), \"./weights/big_autoencoder2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T18:40:25.265697Z",
     "iopub.status.busy": "2022-12-23T18:40:25.265305Z",
     "iopub.status.idle": "2022-12-23T18:40:25.980092Z",
     "shell.execute_reply": "2022-12-23T18:40:25.978816Z",
     "shell.execute_reply.started": "2022-12-23T18:40:25.265657Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(big_autoencoder2(inputs[0])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:18:52.522869Z",
     "iopub.status.busy": "2022-12-24T05:18:52.522448Z",
     "iopub.status.idle": "2022-12-24T05:18:52.529177Z",
     "shell.execute_reply": "2022-12-24T05:18:52.527983Z",
     "shell.execute_reply.started": "2022-12-24T05:18:52.522834Z"
    }
   },
   "outputs": [],
   "source": [
    "class BigMainAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder1, decoder2):\n",
    "        super(BigMainAutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder1 = decoder1\n",
    "        self.decoder2 = decoder2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded1 = self.decoder1(encoded)\n",
    "        decoded2 = self.decoder2(encoded)\n",
    "        return encoded, decoded1, decoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:18:54.711772Z",
     "iopub.status.busy": "2022-12-24T05:18:54.711068Z",
     "iopub.status.idle": "2022-12-24T05:18:54.717299Z",
     "shell.execute_reply": "2022-12-24T05:18:54.716022Z",
     "shell.execute_reply.started": "2022-12-24T05:18:54.711734Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_big_main_model(encoder, decoder1, decoder2):\n",
    "    autoencoder = BigMainAutoEncoder(encoder, decoder1, decoder2)\n",
    "#     print_model(autoencoder.encoder, autoencoder.decoder1, autoencoder.decoder2)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T18:49:31.085675Z",
     "iopub.status.busy": "2022-12-23T18:49:31.085301Z",
     "iopub.status.idle": "2022-12-23T18:49:31.097180Z",
     "shell.execute_reply": "2022-12-23T18:49:31.096106Z",
     "shell.execute_reply.started": "2022-12-23T18:49:31.085640Z"
    }
   },
   "outputs": [],
   "source": [
    "main_model = create_big_main_model(bigger_encoder.encoder, big_autoencoder1.decoder, big_autoencoder2.decoder)\n",
    "main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T18:50:06.751592Z",
     "iopub.status.busy": "2022-12-23T18:50:06.751118Z",
     "iopub.status.idle": "2022-12-23T18:50:06.759611Z",
     "shell.execute_reply": "2022-12-23T18:50:06.758406Z",
     "shell.execute_reply.started": "2022-12-23T18:50:06.751552Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(main_model.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T18:50:31.491533Z",
     "iopub.status.busy": "2022-12-23T18:50:31.490463Z",
     "iopub.status.idle": "2022-12-23T18:50:31.497036Z",
     "shell.execute_reply": "2022-12-23T18:50:31.495422Z",
     "shell.execute_reply.started": "2022-12-23T18:50:31.491487Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(main_model.parameters()):\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T18:50:37.349122Z",
     "iopub.status.busy": "2022-12-23T18:50:37.348762Z",
     "iopub.status.idle": "2022-12-23T18:50:37.355047Z",
     "shell.execute_reply": "2022-12-23T18:50:37.354073Z",
     "shell.execute_reply.started": "2022-12-23T18:50:37.349092Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(main_model.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T18:51:06.753745Z",
     "iopub.status.busy": "2022-12-23T18:51:06.753391Z",
     "iopub.status.idle": "2022-12-23T18:51:06.761630Z",
     "shell.execute_reply": "2022-12-23T18:51:06.760577Z",
     "shell.execute_reply.started": "2022-12-23T18:51:06.753715Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, main_model.parameters()))\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-12-23T18:52:44.970234Z",
     "iopub.status.busy": "2022-12-23T18:52:44.969720Z",
     "iopub.status.idle": "2022-12-23T20:17:33.913940Z",
     "shell.execute_reply": "2022-12-23T20:17:33.912620Z",
     "shell.execute_reply.started": "2022-12-23T18:52:44.970199Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, output1, output2 = main_model(inputs)\n",
    "        loss = (criterion(output1, outputs1) + criterion(output2, outputs2)) / 2\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(main_model.state_dict(), \"./weights/big_main_model.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(main_model.state_dict(), \"./weights/big_main_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T20:23:33.143673Z",
     "iopub.status.busy": "2022-12-23T20:23:33.142989Z",
     "iopub.status.idle": "2022-12-23T20:23:34.280692Z",
     "shell.execute_reply": "2022-12-23T20:23:34.279474Z",
     "shell.execute_reply.started": "2022-12-23T20:23:33.143629Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    loss = (criterion(main_model(inputs[0])[1], outputs1[0]) + criterion(main_model(inputs[0])[2], outputs2[0])) / 2\n",
    "    print(\"loss: \", loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T20:27:33.390562Z",
     "iopub.status.busy": "2022-12-23T20:27:33.390173Z",
     "iopub.status.idle": "2022-12-23T20:27:34.054269Z",
     "shell.execute_reply": "2022-12-23T20:27:34.053173Z",
     "shell.execute_reply.started": "2022-12-23T20:27:33.390526Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    loss = (criterion(main_model(inputs[0])[1], outputs1[0]) + criterion(main_model(inputs[0])[2], outputs2[0])) / 2\n",
    "    print(\"loss: \", loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T20:27:59.733269Z",
     "iopub.status.busy": "2022-12-23T20:27:59.732893Z",
     "iopub.status.idle": "2022-12-23T20:28:00.544794Z",
     "shell.execute_reply": "2022-12-23T20:28:00.543578Z",
     "shell.execute_reply.started": "2022-12-23T20:27:59.733236Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    loss = (criterion(main_model(inputs[0])[1], outputs1[0]) + criterion(main_model(inputs[0])[2], outputs2[0])) / 2\n",
    "    print(\"loss: \", loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T20:29:17.882621Z",
     "iopub.status.busy": "2022-12-23T20:29:17.881515Z",
     "iopub.status.idle": "2022-12-23T20:29:18.599864Z",
     "shell.execute_reply": "2022-12-23T20:29:18.598573Z",
     "shell.execute_reply.started": "2022-12-23T20:29:17.882571Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    loss = (criterion(main_model(inputs[0])[1], outputs1[0]) + criterion(main_model(inputs[0])[2], outputs2[0])) / 2\n",
    "    print(\"loss: \", loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main big model with specific Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:17:03.394906Z",
     "iopub.status.busy": "2022-12-24T05:17:03.394381Z",
     "iopub.status.idle": "2022-12-24T05:17:05.472608Z",
     "shell.execute_reply": "2022-12-24T05:17:05.471619Z",
     "shell.execute_reply.started": "2022-12-24T05:17:03.394865Z"
    }
   },
   "outputs": [],
   "source": [
    "bigger_encoder = create_bigger_model()\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "custom_set = CustomDataset(1000)\n",
    "custom_loader = torch.utils.data.DataLoader(custom_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = CustomDataset(1000)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:17:40.958754Z",
     "iopub.status.busy": "2022-12-24T05:17:40.958343Z",
     "iopub.status.idle": "2022-12-24T05:17:40.975781Z",
     "shell.execute_reply": "2022-12-24T05:17:40.973417Z",
     "shell.execute_reply.started": "2022-12-24T05:17:40.958719Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "bigger_encoder.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/bigger_encoder.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:19:14.027087Z",
     "iopub.status.busy": "2022-12-24T05:19:14.026732Z",
     "iopub.status.idle": "2022-12-24T05:19:14.037479Z",
     "shell.execute_reply": "2022-12-24T05:19:14.036360Z",
     "shell.execute_reply.started": "2022-12-24T05:19:14.027056Z"
    }
   },
   "outputs": [],
   "source": [
    "big_autoencoder1 = create_bigger_model1(bigger_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:19:20.539191Z",
     "iopub.status.busy": "2022-12-24T05:19:20.538518Z",
     "iopub.status.idle": "2022-12-24T05:19:20.564620Z",
     "shell.execute_reply": "2022-12-24T05:19:20.563668Z",
     "shell.execute_reply.started": "2022-12-24T05:19:20.539152Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "big_autoencoder1.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/big_autoencoder1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:19:32.768791Z",
     "iopub.status.busy": "2022-12-24T05:19:32.768415Z",
     "iopub.status.idle": "2022-12-24T05:19:32.777718Z",
     "shell.execute_reply": "2022-12-24T05:19:32.776563Z",
     "shell.execute_reply.started": "2022-12-24T05:19:32.768761Z"
    }
   },
   "outputs": [],
   "source": [
    "big_autoencoder2 = create_bigger_model1(bigger_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:21:56.913518Z",
     "iopub.status.busy": "2022-12-24T05:21:56.912880Z",
     "iopub.status.idle": "2022-12-24T05:21:56.948459Z",
     "shell.execute_reply": "2022-12-24T05:21:56.947377Z",
     "shell.execute_reply.started": "2022-12-24T05:21:56.913476Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "big_autoencoder2.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/big_autoencoder2.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:19:56.944505Z",
     "iopub.status.busy": "2022-12-24T05:19:56.944137Z",
     "iopub.status.idle": "2022-12-24T05:19:56.954708Z",
     "shell.execute_reply": "2022-12-24T05:19:56.953485Z",
     "shell.execute_reply.started": "2022-12-24T05:19:56.944474Z"
    }
   },
   "outputs": [],
   "source": [
    "main_model = create_big_main_model(bigger_encoder.encoder, big_autoencoder1.decoder, big_autoencoder2.decoder)\n",
    "main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:22:49.826586Z",
     "iopub.status.busy": "2022-12-24T05:22:49.826104Z",
     "iopub.status.idle": "2022-12-24T05:22:49.862112Z",
     "shell.execute_reply": "2022-12-24T05:22:49.861250Z",
     "shell.execute_reply.started": "2022-12-24T05:22:49.826543Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading checkpoint...\")\n",
    "main_model.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/big_main_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:22:52.398657Z",
     "iopub.status.busy": "2022-12-24T05:22:52.398287Z",
     "iopub.status.idle": "2022-12-24T05:22:52.404685Z",
     "shell.execute_reply": "2022-12-24T05:22:52.403126Z",
     "shell.execute_reply.started": "2022-12-24T05:22:52.398612Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, main_model.parameters()))\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:23:32.794766Z",
     "iopub.status.busy": "2022-12-24T05:23:32.794380Z",
     "iopub.status.idle": "2022-12-24T05:23:33.511509Z",
     "shell.execute_reply": "2022-12-24T05:23:33.510355Z",
     "shell.execute_reply.started": "2022-12-24T05:23:32.794735Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    loss = (criterion(main_model(inputs[0])[1], outputs1[0]) + criterion(main_model(inputs[0])[2], outputs2[0])) / 2\n",
    "    print(\"loss: \", loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-12-24T05:32:15.086195Z",
     "iopub.status.busy": "2022-12-24T05:32:15.085784Z",
     "iopub.status.idle": "2022-12-24T05:32:15.100260Z",
     "shell.execute_reply": "2022-12-24T05:32:15.098888Z",
     "shell.execute_reply.started": "2022-12-24T05:32:15.086159Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "post_denoiser1 = create_bigger_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T05:32:18.566579Z",
     "iopub.status.busy": "2022-12-24T05:32:18.566106Z",
     "iopub.status.idle": "2022-12-24T05:32:18.575484Z",
     "shell.execute_reply": "2022-12-24T05:32:18.574613Z",
     "shell.execute_reply.started": "2022-12-24T05:32:18.566538Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(post_denoiser1.parameters())\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-12-24T05:33:57.781486Z",
     "iopub.status.busy": "2022-12-24T05:33:57.781071Z",
     "iopub.status.idle": "2022-12-24T05:54:42.381899Z",
     "shell.execute_reply": "2022-12-24T05:54:42.380624Z",
     "shell.execute_reply.started": "2022-12-24T05:33:57.781453Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, main_output1, main_output2 = main_model(inputs)\n",
    "        main_output1 = get_torch_vars(main_output1)\n",
    "        denoise_encoded, denoised_output = post_denoiser1(main_output1[0])\n",
    "        loss = criterion(denoised_output, outputs1)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch_counter == 4:\n",
    "        epoch_counter = -1\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(post_denoiser1.state_dict(), \"./weights/post_denoiser1.pkl\")\n",
    "    epoch_counter += 1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(post_denoiser1.state_dict(), \"./weights/post_denoiser1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:30:06.263963Z",
     "iopub.status.busy": "2023-01-03T07:30:06.263584Z",
     "iopub.status.idle": "2023-01-03T07:30:06.273317Z",
     "shell.execute_reply": "2023-01-03T07:30:06.272304Z",
     "shell.execute_reply.started": "2023-01-03T07:30:06.263931Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 3, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 3, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 3, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(48, 96, 3, padding=1),           # [batch, 96, 2, 2]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 3, padding=1),  # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 3, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 3, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 3, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:30:07.033677Z",
     "iopub.status.busy": "2023-01-03T07:30:07.033335Z",
     "iopub.status.idle": "2023-01-03T07:30:07.038920Z",
     "shell.execute_reply": "2023-01-03T07:30:07.037907Z",
     "shell.execute_reply.started": "2023-01-03T07:30:07.033648Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bigger_model():\n",
    "    autoencoder = ConvAutoEncoder()\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:30:10.727647Z",
     "iopub.status.busy": "2023-01-03T07:30:10.727013Z",
     "iopub.status.idle": "2023-01-03T07:30:30.630513Z",
     "shell.execute_reply": "2023-01-03T07:30:30.629425Z",
     "shell.execute_reply.started": "2023-01-03T07:30:10.727611Z"
    }
   },
   "outputs": [],
   "source": [
    "bigger_encoder = create_bigger_model()\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    ])\n",
    "\n",
    "custom_set = CustomDataset(1000, transform)\n",
    "custom_loader = torch.utils.data.DataLoader(custom_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = CustomDataset(1000, transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T23:03:52.260951Z",
     "iopub.status.busy": "2023-01-02T23:03:52.260591Z",
     "iopub.status.idle": "2023-01-02T23:03:52.279664Z",
     "shell.execute_reply": "2023-01-02T23:03:52.278614Z",
     "shell.execute_reply.started": "2023-01-02T23:03:52.260915Z"
    }
   },
   "outputs": [],
   "source": [
    "bigger_encoder.load_state_dict(torch.load(\"/kaggle/input/cifar10-encoder/weights/bigger_encoder.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:34:23.883022Z",
     "iopub.status.busy": "2023-01-03T07:34:23.882624Z",
     "iopub.status.idle": "2023-01-03T07:34:23.889294Z",
     "shell.execute_reply": "2023-01-03T07:34:23.888253Z",
     "shell.execute_reply.started": "2023-01-03T07:34:23.882989Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(bigger_encoder.parameters())\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:35:02.787508Z",
     "iopub.status.busy": "2023-01-03T07:35:02.787130Z",
     "iopub.status.idle": "2023-01-03T07:50:09.851721Z",
     "shell.execute_reply": "2023-01-03T07:50:09.850549Z",
     "shell.execute_reply.started": "2023-01-03T07:35:02.787474Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, _) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = bigger_encoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(bigger_encoder.state_dict(), \"./weights/3bigger_encoder.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(bigger_encoder.state_dict(), \"./weights/3bigger_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:51:54.010543Z",
     "iopub.status.busy": "2023-01-03T07:51:54.010158Z",
     "iopub.status.idle": "2023-01-03T07:51:54.414117Z",
     "shell.execute_reply": "2023-01-03T07:51:54.412565Z",
     "shell.execute_reply.started": "2023-01-03T07:51:54.010508Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    print(inputs[0].std())\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(bigger_encoder(inputs[0])[1])\n",
    "    loss = criterion(bigger_encoder(inputs[0])[1], inputs[0])\n",
    "    print(\"Loss:\", loss.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:50:10.422585Z",
     "iopub.status.busy": "2023-01-03T07:50:10.419867Z",
     "iopub.status.idle": "2023-01-03T07:50:10.433942Z",
     "shell.execute_reply": "2023-01-03T07:50:10.433038Z",
     "shell.execute_reply.started": "2023-01-03T07:50:10.422544Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder1(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(ConvAutoEncoder1, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 3, padding=1),  # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 3, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 3, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 3, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:50:10.444113Z",
     "iopub.status.busy": "2023-01-03T07:50:10.440907Z",
     "iopub.status.idle": "2023-01-03T07:50:10.452342Z",
     "shell.execute_reply": "2023-01-03T07:50:10.450969Z",
     "shell.execute_reply.started": "2023-01-03T07:50:10.444049Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_conv_model1(encoder):\n",
    "    autoencoder = ConvAutoEncoder1(encoder)\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:50:10.460000Z",
     "iopub.status.busy": "2023-01-03T07:50:10.457402Z",
     "iopub.status.idle": "2023-01-03T07:50:10.473630Z",
     "shell.execute_reply": "2023-01-03T07:50:10.472859Z",
     "shell.execute_reply.started": "2023-01-03T07:50:10.459963Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_autoencoder1 = create_conv_model1(bigger_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:50:10.493454Z",
     "iopub.status.busy": "2023-01-03T07:50:10.490963Z",
     "iopub.status.idle": "2023-01-03T07:50:10.503128Z",
     "shell.execute_reply": "2023-01-03T07:50:10.502075Z",
     "shell.execute_reply.started": "2023-01-03T07:50:10.493418Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(conv_autoencoder1.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:50:10.507896Z",
     "iopub.status.busy": "2023-01-03T07:50:10.506386Z",
     "iopub.status.idle": "2023-01-03T07:50:10.515716Z",
     "shell.execute_reply": "2023-01-03T07:50:10.514694Z",
     "shell.execute_reply.started": "2023-01-03T07:50:10.507860Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(conv_autoencoder1.parameters()):\n",
    "    if index < 8:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:53:39.302138Z",
     "iopub.status.busy": "2023-01-03T07:53:39.301478Z",
     "iopub.status.idle": "2023-01-03T07:53:39.311259Z",
     "shell.execute_reply": "2023-01-03T07:53:39.310120Z",
     "shell.execute_reply.started": "2023-01-03T07:53:39.302086Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(conv_autoencoder1.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:53:58.415252Z",
     "iopub.status.busy": "2023-01-03T07:53:58.414832Z",
     "iopub.status.idle": "2023-01-03T07:53:58.421041Z",
     "shell.execute_reply": "2023-01-03T07:53:58.420031Z",
     "shell.execute_reply.started": "2023-01-03T07:53:58.415218Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, conv_autoencoder1.parameters()))\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T07:54:43.921829Z",
     "iopub.status.busy": "2023-01-03T07:54:43.920794Z",
     "iopub.status.idle": "2023-01-03T08:21:20.198694Z",
     "shell.execute_reply": "2023-01-03T08:21:20.197411Z",
     "shell.execute_reply.started": "2023-01-03T07:54:43.921789Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = conv_autoencoder1(inputs)\n",
    "        loss = criterion(outputs, outputs1)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch_counter == 4:\n",
    "        epoch_counter = -1\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(conv_autoencoder1.state_dict(), \"./weights/conv_autoencoder1.pkl\")\n",
    "    epoch_counter += 1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(conv_autoencoder1.state_dict(), \"./weights/conv_autoencoder1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:48:12.154181Z",
     "iopub.status.busy": "2023-01-03T08:48:12.153465Z",
     "iopub.status.idle": "2023-01-03T08:48:12.649165Z",
     "shell.execute_reply": "2023-01-03T08:48:12.648099Z",
     "shell.execute_reply.started": "2023-01-03T08:48:12.154129Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    print(inputs[0].std())\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"Image 1: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(conv_autoencoder1(inputs[0])[1])\n",
    "    loss = criterion(conv_autoencoder1(inputs[0])[1], outputs1[0])\n",
    "    print(\"Loss:\", loss.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:21:20.206329Z",
     "iopub.status.busy": "2023-01-03T08:21:20.204018Z",
     "iopub.status.idle": "2023-01-03T08:21:20.220786Z",
     "shell.execute_reply": "2023-01-03T08:21:20.219488Z",
     "shell.execute_reply.started": "2023-01-03T08:21:20.206286Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_autoencoder2 = create_conv_model1(bigger_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:21:20.244904Z",
     "iopub.status.busy": "2023-01-03T08:21:20.242711Z",
     "iopub.status.idle": "2023-01-03T08:21:20.254650Z",
     "shell.execute_reply": "2023-01-03T08:21:20.253593Z",
     "shell.execute_reply.started": "2023-01-03T08:21:20.244861Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(conv_autoencoder2.parameters()):\n",
    "    print(index, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:21:20.259755Z",
     "iopub.status.busy": "2023-01-03T08:21:20.259053Z",
     "iopub.status.idle": "2023-01-03T08:21:20.268091Z",
     "shell.execute_reply": "2023-01-03T08:21:20.267076Z",
     "shell.execute_reply.started": "2023-01-03T08:21:20.259719Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, conv_autoencoder2.parameters()))\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:21:43.066819Z",
     "iopub.status.busy": "2023-01-03T08:21:43.065893Z",
     "iopub.status.idle": "2023-01-03T08:48:12.151247Z",
     "shell.execute_reply": "2023-01-03T08:48:12.149933Z",
     "shell.execute_reply.started": "2023-01-03T08:21:43.066781Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = conv_autoencoder2(inputs)\n",
    "        loss = criterion(outputs, outputs2)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch_counter == 4:\n",
    "        epoch_counter = -1\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(conv_autoencoder2.state_dict(), \"./weights/conv_autoencoder2.pkl\")\n",
    "    epoch_counter += 1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(conv_autoencoder2.state_dict(), \"./weights/conv_autoencoder2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:48:12.651564Z",
     "iopub.status.busy": "2023-01-03T08:48:12.651179Z",
     "iopub.status.idle": "2023-01-03T08:48:13.213049Z",
     "shell.execute_reply": "2023-01-03T08:48:13.211927Z",
     "shell.execute_reply.started": "2023-01-03T08:48:12.651525Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    print(inputs[0].std())\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"Image 2: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(conv_autoencoder2(inputs[0])[1])\n",
    "    loss = criterion(conv_autoencoder2(inputs[0])[1], outputs2[0])\n",
    "    print(\"Loss:\", loss.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:48:13.215891Z",
     "iopub.status.busy": "2023-01-03T08:48:13.215497Z",
     "iopub.status.idle": "2023-01-03T08:48:14.282833Z",
     "shell.execute_reply": "2023-01-03T08:48:14.281489Z",
     "shell.execute_reply.started": "2023-01-03T08:48:13.215830Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"Image 1: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"Predicted image 1: \")\n",
    "    imshow(conv_autoencoder1(inputs[0])[1])\n",
    "    print(\"Image 2:\")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"Predicted image 2:\")\n",
    "    imshow(conv_autoencoder2(inputs[0])[1])\n",
    "    loss = (criterion(conv_autoencoder1(inputs[0])[1], outputs1[0]) + criterion(conv_autoencoder2(inputs[0])[1], outputs2[0]))/2\n",
    "    print(\"Loss:\", loss.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:50:34.710902Z",
     "iopub.status.busy": "2023-01-03T08:50:34.710502Z",
     "iopub.status.idle": "2023-01-03T08:50:34.717082Z",
     "shell.execute_reply": "2023-01-03T08:50:34.716058Z",
     "shell.execute_reply.started": "2023-01-03T08:50:34.710860Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvMainAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder1, decoder2):\n",
    "        super(ConvMainAutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder1 = decoder1\n",
    "        self.decoder2 = decoder2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded1 = self.decoder1(encoded)\n",
    "        decoded2 = self.decoder2(encoded)\n",
    "        return encoded, decoded1, decoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:50:49.341453Z",
     "iopub.status.busy": "2023-01-03T08:50:49.341087Z",
     "iopub.status.idle": "2023-01-03T08:50:49.347085Z",
     "shell.execute_reply": "2023-01-03T08:50:49.346051Z",
     "shell.execute_reply.started": "2023-01-03T08:50:49.341420Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_conv_main_model(encoder, decoder1, decoder2):\n",
    "    autoencoder = ConvMainAutoEncoder(encoder, decoder1, decoder2)\n",
    "#     print_model(autoencoder.encoder, autoencoder.decoder1, autoencoder.decoder2)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:52:29.943951Z",
     "iopub.status.busy": "2023-01-03T08:52:29.943542Z",
     "iopub.status.idle": "2023-01-03T08:52:29.954727Z",
     "shell.execute_reply": "2023-01-03T08:52:29.953628Z",
     "shell.execute_reply.started": "2023-01-03T08:52:29.943912Z"
    }
   },
   "outputs": [],
   "source": [
    "main_model = create_conv_main_model(bigger_encoder.encoder, conv_autoencoder1.decoder, conv_autoencoder2.decoder)\n",
    "main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:53:25.591702Z",
     "iopub.status.busy": "2023-01-03T08:53:25.591291Z",
     "iopub.status.idle": "2023-01-03T08:53:25.600528Z",
     "shell.execute_reply": "2023-01-03T08:53:25.599366Z",
     "shell.execute_reply.started": "2023-01-03T08:53:25.591658Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(main_model.parameters()):\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:54:33.525750Z",
     "iopub.status.busy": "2023-01-03T08:54:33.525379Z",
     "iopub.status.idle": "2023-01-03T08:54:33.533025Z",
     "shell.execute_reply": "2023-01-03T08:54:33.532001Z",
     "shell.execute_reply.started": "2023-01-03T08:54:33.525716Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(main_model.parameters())\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T08:55:40.909227Z",
     "iopub.status.busy": "2023-01-03T08:55:40.908855Z",
     "iopub.status.idle": "2023-01-03T10:20:47.659050Z",
     "shell.execute_reply": "2023-01-03T10:20:47.656944Z",
     "shell.execute_reply.started": "2023-01-03T08:55:40.909196Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, output1, output2 = main_model(inputs)\n",
    "        loss = (criterion(output1, outputs1) + criterion(output2, outputs2)) / 2\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(main_model.state_dict(), \"./weights/conv_main_model.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(main_model.state_dict(), \"./weights/conv_main_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T10:20:47.663179Z",
     "iopub.status.busy": "2023-01-03T10:20:47.661350Z",
     "iopub.status.idle": "2023-01-03T10:20:48.373209Z",
     "shell.execute_reply": "2023-01-03T10:20:48.372079Z",
     "shell.execute_reply.started": "2023-01-03T10:20:47.663120Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (inputs, (outputs1, outputs2)) in enumerate(test_loader, 0):\n",
    "    inputs = get_torch_vars(inputs)\n",
    "    outputs1 = get_torch_vars(outputs1)\n",
    "    outputs2 = get_torch_vars(outputs2)\n",
    "    print(\"mean image: \")\n",
    "    imshow(inputs[0])\n",
    "    print(\"first image: \")\n",
    "    imshow(outputs1[0])\n",
    "    print(\"second image: \")\n",
    "    imshow(outputs2[0])\n",
    "    print(\"predicted image 1: \")\n",
    "    imshow(main_model(inputs[0])[1])\n",
    "    print(\"predicted image 2: \")\n",
    "    imshow(main_model(inputs[0])[2])\n",
    "    loss = (criterion(main_model(inputs[0])[1], outputs1[0]) + criterion(main_model(inputs[0])[2], outputs2[0])) / 2\n",
    "    print(\"loss: \", loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:18:22.295104Z",
     "iopub.status.busy": "2023-01-03T19:18:22.294510Z",
     "iopub.status.idle": "2023-01-03T19:18:22.304873Z",
     "shell.execute_reply": "2023-01-03T19:18:22.303761Z",
     "shell.execute_reply.started": "2023-01-03T19:18:22.295066Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 3, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 3, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 3, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(48, 96, 3, padding=1),           # [batch, 96, 2, 2]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 3, padding=1),  # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 3, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 3, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 3, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:19:11.760465Z",
     "iopub.status.busy": "2023-01-03T19:19:11.759403Z",
     "iopub.status.idle": "2023-01-03T19:19:11.766577Z",
     "shell.execute_reply": "2023-01-03T19:19:11.765513Z",
     "shell.execute_reply.started": "2023-01-03T19:19:11.760420Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_conv_model():\n",
    "    autoencoder = ConvAutoEncoder()\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:20:08.743101Z",
     "iopub.status.busy": "2023-01-03T19:20:08.742744Z",
     "iopub.status.idle": "2023-01-03T19:20:11.199103Z",
     "shell.execute_reply": "2023-01-03T19:20:11.198044Z",
     "shell.execute_reply.started": "2023-01-03T19:20:08.743071Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_encoder = create_conv_model()\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    ])\n",
    "\n",
    "custom_set = CustomDataset(1000, transform)\n",
    "custom_loader = torch.utils.data.DataLoader(custom_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = CustomDataset(1000, transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:24:48.828316Z",
     "iopub.status.busy": "2023-01-03T19:24:48.827823Z",
     "iopub.status.idle": "2023-01-03T19:24:48.838075Z",
     "shell.execute_reply": "2023-01-03T19:24:48.837006Z",
     "shell.execute_reply.started": "2023-01-03T19:24:48.828260Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(conv_encoder.parameters())\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T19:24:53.589194Z",
     "iopub.status.busy": "2023-01-03T19:24:53.588508Z",
     "iopub.status.idle": "2023-01-03T20:37:58.921975Z",
     "shell.execute_reply": "2023-01-03T20:37:58.920057Z",
     "shell.execute_reply.started": "2023-01-03T19:24:53.589158Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, _) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = conv_encoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_counter += 1\n",
    "    if epoch_counter == 4:\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(conv_encoder.state_dict(), \"./weights/conv_encoder.pkl\")\n",
    "        epoch_counter = -1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(conv_encoder.state_dict(), \"./weights/conv_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:48:10.084616Z",
     "iopub.status.busy": "2023-01-03T20:48:10.083968Z",
     "iopub.status.idle": "2023-01-03T20:48:10.100301Z",
     "shell.execute_reply": "2023-01-03T20:48:10.099077Z",
     "shell.execute_reply.started": "2023-01-03T20:48:10.084561Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeepConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(DeepConvAutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 72, 3, padding=1),  # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(72, 60, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(60, 48, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 36, 3, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(36, 24, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 3, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 6, 3, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(6, 3, 3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:48:10.903688Z",
     "iopub.status.busy": "2023-01-03T20:48:10.903235Z",
     "iopub.status.idle": "2023-01-03T20:48:10.909734Z",
     "shell.execute_reply": "2023-01-03T20:48:10.908516Z",
     "shell.execute_reply.started": "2023-01-03T20:48:10.903629Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_deep_model(encoder):\n",
    "    autoencoder = DeepConvAutoEncoder(encoder)\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:48:11.436276Z",
     "iopub.status.busy": "2023-01-03T20:48:11.435860Z",
     "iopub.status.idle": "2023-01-03T20:48:11.455025Z",
     "shell.execute_reply": "2023-01-03T20:48:11.453329Z",
     "shell.execute_reply.started": "2023-01-03T20:48:11.436239Z"
    }
   },
   "outputs": [],
   "source": [
    "deep_autoencoder1 = create_deep_model(conv_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:48:15.637584Z",
     "iopub.status.busy": "2023-01-03T20:48:15.637211Z",
     "iopub.status.idle": "2023-01-03T20:48:15.642738Z",
     "shell.execute_reply": "2023-01-03T20:48:15.641516Z",
     "shell.execute_reply.started": "2023-01-03T20:48:15.637551Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, param in enumerate(deep_autoencoder1.parameters()):\n",
    "    if index < 8:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:48:31.942818Z",
     "iopub.status.busy": "2023-01-03T20:48:31.942432Z",
     "iopub.status.idle": "2023-01-03T20:48:31.948190Z",
     "shell.execute_reply": "2023-01-03T20:48:31.947218Z",
     "shell.execute_reply.started": "2023-01-03T20:48:31.942784Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, deep_autoencoder1.parameters()))\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:48:33.542575Z",
     "iopub.status.busy": "2023-01-03T20:48:33.542224Z",
     "iopub.status.idle": "2023-01-03T21:19:21.513974Z",
     "shell.execute_reply": "2023-01-03T21:19:21.512716Z",
     "shell.execute_reply.started": "2023-01-03T20:48:33.542544Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_counter = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, (outputs1, outputs2)) in enumerate(custom_loader, 0):\n",
    "        inputs = get_torch_vars(inputs)\n",
    "        outputs1 = get_torch_vars(outputs1)\n",
    "        outputs2 = get_torch_vars(outputs2)\n",
    "        # ============ Forward ============\n",
    "        encoded, outputs = deep_autoencoder1(inputs)\n",
    "        loss = criterion(outputs, outputs1)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch_counter == 4:\n",
    "        epoch_counter = -1\n",
    "        if not os.path.exists('./weights'):\n",
    "            os.mkdir('./weights')\n",
    "        torch.save(deep_autoencoder1.state_dict(), \"./weights/deep_autoencoder1.pkl\")\n",
    "    epoch_counter += 1\n",
    "print('Finished Training')\n",
    "print('Saving Model...')\n",
    "if not os.path.exists('./weights'):\n",
    "    os.mkdir('./weights')\n",
    "torch.save(deep_autoencoder1.state_dict(), \"./weights/deep_autoencoder1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
